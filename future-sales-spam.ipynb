{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8587,"databundleVersionId":868304,"sourceType":"competition"},{"sourceId":10562034,"sourceType":"datasetVersion","datasetId":6534960},{"sourceId":214226817,"sourceType":"kernelVersion"}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installing LightGBM with GPU","metadata":{}},{"cell_type":"code","source":"# Monitor memory usage\nmemory_stats = []\nfor name, value in list(locals().items()):\n    try:\n        if isinstance(value, cudf.DataFrame):\n            size = value.memory_usage(deep=True).sum()\n        else:\n            size = sys.getsizeof(value)\n        memory_stats.append((name, size))\n    except Exception:\n        pass\n\nmemory_stats.sort(key=lambda x : -x[1])\nprint(memory_stats)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T22:47:02.019022Z","iopub.execute_input":"2025-01-24T22:47:02.019536Z","iopub.status.idle":"2025-01-24T22:47:02.025016Z","shell.execute_reply.started":"2025-01-24T22:47:02.019514Z","shell.execute_reply":"2025-01-24T22:47:02.024177Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Starting Loads","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error\nimport itertools\nimport lightgbm as lgb\nimport sys\nimport time\nfrom catboost import CatBoostClassifier, Pool\nimport sys \nimport os ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:42:56.608738Z","iopub.execute_input":"2025-01-25T15:42:56.608946Z","iopub.status.idle":"2025-01-25T15:43:22.541521Z","shell.execute_reply.started":"2025-01-25T15:42:56.608926Z","shell.execute_reply":"2025-01-25T15:43:22.540849Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys \nimport os ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:43:53.918748Z","iopub.execute_input":"2025-01-25T15:43:53.919048Z","iopub.status.idle":"2025-01-25T15:43:53.922087Z","shell.execute_reply.started":"2025-01-25T15:43:53.919027Z","shell.execute_reply":"2025-01-25T15:43:53.921202Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cudf\nimport cuml\nprint(cudf.__version__, cuml.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:43:54.126576Z","iopub.execute_input":"2025-01-25T15:43:54.126878Z","iopub.status.idle":"2025-01-25T15:44:12.435955Z","shell.execute_reply.started":"2025-01-25T15:43:54.126851Z","shell.execute_reply":"2025-01-25T15:44:12.435153Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DIRECTORY = '/kaggle/input/competitive-data-science-predict-future-sales/'\nTRANSLATED = '/kaggle/input/future-sales-translated/'\ncategories = pd.read_csv(TRANSLATED + 'item_categories.csv').drop(columns={'Unnamed: 0'})\nitems = pd.read_csv(TRANSLATED + 'items.csv').drop(columns={'Unnamed: 0'})\nshops = pd.read_csv(TRANSLATED + 'shops.csv').drop(columns={'Unnamed: 0'})\ntrain = pd.read_csv(DIRECTORY + 'sales_train.csv')\ntest = pd.read_csv(DIRECTORY + 'test.csv')\ntrain['date'] = pd.to_datetime(train['date'], format='%d.%m.%Y')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:45:56.510226Z","iopub.execute_input":"2025-01-25T15:45:56.510521Z","iopub.status.idle":"2025-01-25T15:45:58.115218Z","shell.execute_reply.started":"2025-01-25T15:45:56.510501Z","shell.execute_reply":"2025-01-25T15:45:58.11423Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Categorical Groupings\n\nNote: All done in pandas (so string ops are supported) - its fast anyways","metadata":{}},{"cell_type":"code","source":"# Outlier clipping\ntrain['item_cnt_day_clipped'] = np.clip(train['item_cnt_day'], 0, 20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:45:59.711773Z","iopub.execute_input":"2025-01-25T15:45:59.712092Z","iopub.status.idle":"2025-01-25T15:45:59.756156Z","shell.execute_reply.started":"2025-01-25T15:45:59.712069Z","shell.execute_reply":"2025-01-25T15:45:59.755463Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"items_combined = pd.merge(left=items, right=categories, on=['item_category_id'], how='outer')\nprint(\"Na values:\", items_combined.isna().sum().sum()) # check that nothing missing\n\n# lowercase (modifying in place)\nitems_combined['item_name'] = items_combined['item_name'].str.lower()\nitems_combined['item_category_name'] = items_combined['item_category_name'].str.lower()\n\n# item name\nitems_combined['item_name_cleaned'] = items_combined['item_name'].str.replace(r'[\\s\\W]', '', regex=True)\nprefixes = [4,8,11]\nfor prefix in prefixes:\n    items_combined[f'item_name_{prefix}'] = items_combined['item_name_cleaned'].str[:prefix]\n# items_combined.head()\n\n# category name\nitems_combined['category_first'] = items_combined['item_category_name'].str.split(r'[\\-\\(]', regex=True).str[0].str.strip()\nitems_combined['category_second'] = items_combined['item_category_name'].str.split(r'[\\-\\(]', regex=True).str[1].str.strip()\n# items_combined.head()\n\n# shop\nshops = pd.DataFrame(shops)\nshops['shop_name'] = shops['shop_name'].str.lower().replace(r'[\\,\\.\\!]', '', regex=True)\nshops['shop_first'] = shops['shop_name'].str.split().str[0]\nshops['shop_second'] = shops['shop_name'].str.split().str[1]\nshops['shop_parenthesis'] = shops['shop_name'].str.extract(r'\\\"(.*)\\\"')\n# shops.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:46:01.892359Z","iopub.execute_input":"2025-01-25T15:46:01.892647Z","iopub.status.idle":"2025-01-25T15:46:02.200333Z","shell.execute_reply.started":"2025-01-25T15:46:01.892627Z","shell.execute_reply":"2025-01-25T15:46:02.199599Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Setting up Test Df\n1. Create all unique store/item combos per month (switch to cudf now)\n2. Spam features (all in cudf)","metadata":{}},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:46:04.158468Z","iopub.execute_input":"2025-01-25T15:46:04.158881Z","iopub.status.idle":"2025-01-25T15:46:04.207919Z","shell.execute_reply.started":"2025-01-25T15:46:04.158845Z","shell.execute_reply":"2025-01-25T15:46:04.207132Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n\ncombos = []\nfor month in train['date_block_num'].unique():\n    month_items = train[train['date_block_num'] == month]['item_id'].unique()\n    month_shops = train[train['date_block_num'] == month]['shop_id'].unique()\n\n    combos.append(np.array(list(itertools.product(month_items, month_shops, [month]))))\n    \nmonth_items = test['item_id'].unique()\nmonth_shops = test['shop_id'].unique()\n\ncombos.append(np.array(list(itertools.product(month_items, month_shops, [34]))))\n\n\naggregated = cudf.DataFrame(data=np.vstack(combos), columns=['item_id', 'shop_id', 'date_block_num'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:47:01.369953Z","iopub.execute_input":"2025-01-25T15:47:01.370242Z","iopub.status.idle":"2025-01-25T15:47:07.739546Z","shell.execute_reply.started":"2025-01-25T15:47:01.370222Z","shell.execute_reply":"2025-01-25T15:47:07.73877Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert stuff over to cudf\ndfs = [items_combined, shops]\nfor df in dfs:\n    for col in df.select_dtypes('object').columns:\n        df[col], _ = df[col].factorize()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:47:23.927199Z","iopub.execute_input":"2025-01-25T15:47:23.927519Z","iopub.status.idle":"2025-01-25T15:47:23.964595Z","shell.execute_reply.started":"2025-01-25T15:47:23.927493Z","shell.execute_reply":"2025-01-25T15:47:23.963978Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_monthly = train.groupby(['shop_id', 'item_id', 'date_block_num'])['item_cnt_day'].sum().to_frame('month_sales').reset_index()\naggregated = aggregated.merge(cudf.from_pandas(train_monthly), how='left').fillna(0)\naggregated['month_sales'] = np.clip(aggregated['month_sales'], 0, 20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:47:25.474246Z","iopub.execute_input":"2025-01-25T15:47:25.474629Z","iopub.status.idle":"2025-01-25T15:47:26.550978Z","shell.execute_reply.started":"2025-01-25T15:47:25.474599Z","shell.execute_reply":"2025-01-25T15:47:26.550283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n# starting aggregation df\n\naggregated = aggregated.merge(cudf.from_pandas(items_combined), on=['item_id']).merge(cudf.from_pandas(shops), on=['shop_id'])\naggregated[['category_second', 'shop_parenthesis']] = aggregated[['category_second', 'shop_parenthesis']].fillna('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:47:28.781338Z","iopub.execute_input":"2025-01-25T15:47:28.781626Z","iopub.status.idle":"2025-01-25T15:47:28.920512Z","shell.execute_reply.started":"2025-01-25T15:47:28.781604Z","shell.execute_reply":"2025-01-25T15:47:28.919632Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compress_dataframe(df):\n    for col in df.select_dtypes(include=['object']).columns:\n        df[col], _ = cudf.factorize(df[col])\n    \n    for col in df.select_dtypes(include=['float64', 'int64']).columns:\n        if df[col].dtype == 'float64':\n            df[col] = cudf.to_numeric(df[col], downcast='float')\n        elif df[col].dtype == 'int64':\n            df[col] = cudf.to_numeric(df[col], downcast='integer')\n    \n    return df\n\nprint(\"Memory before:\", aggregated.memory_usage().sum() / (1024**2), \"MB\")\naggregated = compress_dataframe(aggregated)\nprint(\"Memory after:\", aggregated.memory_usage().sum() / (1024**2), \"MB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:47:31.939924Z","iopub.execute_input":"2025-01-25T15:47:31.940224Z","iopub.status.idle":"2025-01-25T15:47:32.180788Z","shell.execute_reply.started":"2025-01-25T15:47:31.940202Z","shell.execute_reply":"2025-01-25T15:47:32.179938Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n\n# Lagged month_sale features\n\ndef lag_by(df: cudf.DataFrame, group_by_cols: list, time_shift: int):\n    combined_cols = group_by_cols + ['date_block_num']\n    \n    grouped = df.groupby(combined_cols)['month_sales'].mean().to_frame('lag_sales').reset_index()\n    grouped['date_block_num'] = grouped['date_block_num'] + time_shift\n    res = df.merge(right=grouped, on=combined_cols, how='left')['lag_sales'].fillna(-1)\n    return res\n\ngroupings = [['item_id'], ['item_category_id'], ['shop_id'], ['item_name_4'], ['item_name_8'], ['item_name_11'], ['shop_first'], ['category_first'], ['category_second']] \\\n                + [['item_id', 'shop_id'], ['item_category_id', 'shop_id'], ['item_name_4', 'shop_id'], ['shop_id', 'category_first']]\n\nfor window, grouping in itertools.product([1,2,12], groupings):\n    print(window, grouping)\n    subset = aggregated[grouping + ['date_block_num', 'month_sales']]\n    aggregated[f'{window}_rolling({\"\".join(grouping)})'] = \\\n        lag_by(subset, grouping, window).values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:47:44.449485Z","iopub.execute_input":"2025-01-25T15:47:44.449835Z","iopub.status.idle":"2025-01-25T15:48:00.040182Z","shell.execute_reply.started":"2025-01-25T15:47:44.449806Z","shell.execute_reply":"2025-01-25T15:48:00.039443Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n\n# Steps\n# 1. Add FIRST SALE column (item id, or item-store combo)\n# 2. Shift by 1-12 months, then groupby various ages\n\n# Sales in first month (generalized to age since??)\n# ex. sales in first month for an item id (first time item appears)\n# ex. sales in first month for item id - store id combo (first time both sold)\n\n# Groupings\n# for an item-first 4, item-first 8, item category, sales in first month for (item, item-store combo)\n\n# Important: can only include as col if THIS MONTH NOT FIRST MONTH \n\nfirst_sale_item = aggregated[aggregated['month_sales'] > 0].groupby('item_id')['date_block_num'].min().to_frame('first').reset_index()\nfirst_sale_item_shop = aggregated[aggregated['month_sales'] > 0].groupby(['item_id', 'shop_id'])['date_block_num'].min().to_frame('first').reset_index()\n\naggregated['first_item_sale'] = aggregated[['item_id']].merge(first_sale_item, on=['item_id'], how='left')['first']\naggregated['first_item_shop_sale'] = aggregated[['item_id', 'shop_id']].merge(first_sale_item_shop, on=['item_id', 'shop_id'], how='left')['first']\n\naggregated['item_age'] = aggregated['date_block_num'] - aggregated['first_item_sale']\naggregated['item_shop_age'] = aggregated['date_block_num'] - aggregated['first_item_shop_sale']\naggregated = aggregated.fillna(-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:48:02.335792Z","iopub.execute_input":"2025-01-25T15:48:02.336104Z","iopub.status.idle":"2025-01-25T15:48:02.849348Z","shell.execute_reply.started":"2025-01-25T15:48:02.336083Z","shell.execute_reply":"2025-01-25T15:48:02.848449Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\ndef lag_age(df: cudf.DataFrame, group_by_cols: list, time_shift: int, age_col):\n    combined_cols = group_by_cols + ['date_block_num', age_col]\n    \n    grouped = df.groupby(combined_cols)['month_sales'].mean().to_frame('lag_sales').reset_index()\n    grouped['date_block_num'] = grouped['date_block_num'] + time_shift\n    res = df.merge(right=grouped, on=combined_cols, how='left')['lag_sales'].fillna(-1)\n    return res\n\nage_groupings = [['item_category_id'], ['item_name_4']] \\\n                + [['item_id', 'shop_id'], ['item_name_4', 'shop_id'],['item_category_id', 'shop_id']] \\\n                + [['category_first', 'shop_id'], ['category_first']]\n\nfor grouping in age_groupings:\n    for window in [1,2,12]:\n        for age_col in ['item_age', 'item_shop_age']:\n            print(grouping, window, age_col)\n            subset = aggregated[grouping + ['date_block_num', age_col, 'month_sales']]\n            aggregated[f'age{window}_{age_col}_({\"\".join(grouping)})'] = \\\n                lag_age(subset, grouping, window, age_col).values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:48:57.707978Z","iopub.execute_input":"2025-01-25T15:48:57.708291Z","iopub.status.idle":"2025-01-25T15:49:23.846368Z","shell.execute_reply.started":"2025-01-25T15:48:57.708268Z","shell.execute_reply":"2025-01-25T15:49:23.845462Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Clean Final Df and Model","metadata":{}},{"cell_type":"code","source":"final_df = aggregated\n\ndef compress_dataframe(df):\n    for col in df.select_dtypes(include=['object']).columns:\n        df[col], _ = cudf.factorize(df[col])\n    \n    for col in df.select_dtypes(include=['float64', 'int64']).columns:\n        if df[col].dtype == 'float64':\n            df[col] = cudf.to_numeric(df[col], downcast='float')\n        elif df[col].dtype == 'int64':\n            df[col] = cudf.to_numeric(df[col], downcast='integer')\n    \n    return df\n\nprint(\"Memory before:\", final_df.memory_usage().sum() / (1024**2), \"MB\")\nfinal_df = compress_dataframe(final_df)\nprint(\"Memory after:\", final_df.memory_usage().sum() / (1024**2), \"MB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:49:30.894106Z","iopub.execute_input":"2025-01-25T15:49:30.894436Z","iopub.status.idle":"2025-01-25T15:49:31.773496Z","shell.execute_reply.started":"2025-01-25T15:49:30.89441Z","shell.execute_reply":"2025-01-25T15:49:31.772768Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_df.to_pandas().to_pickle('final_df.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:49:35.44684Z","iopub.execute_input":"2025-01-25T15:49:35.447155Z","iopub.status.idle":"2025-01-25T15:49:45.413634Z","shell.execute_reply.started":"2025-01-25T15:49:35.447129Z","shell.execute_reply":"2025-01-25T15:49:45.412738Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare dfs\ntrain, val, test = final_df[(final_df['date_block_num'] < 33) & (final_df['date_block_num'] > 1)], final_df[final_df['date_block_num'] == 33], final_df[final_df['date_block_num'] == 34]\nX_train, Y_train = train.drop(columns='month_sales'), train['month_sales']\nX_val, Y_val = val.drop(columns='month_sales'), val['month_sales']\nX_test, Y_test = test.drop(columns='month_sales'), test['month_sales']\n\nX_train = X_train.to_pandas()\nY_train = Y_train.to_pandas()\nX_val = X_val.to_pandas()\nY_val = Y_val.to_pandas()\nX_test = X_test.to_pandas()\nY_test = Y_test.to_pandas()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:51:56.554003Z","iopub.execute_input":"2025-01-25T15:51:56.554347Z","iopub.status.idle":"2025-01-25T15:52:04.955477Z","shell.execute_reply.started":"2025-01-25T15:51:56.554322Z","shell.execute_reply":"2025-01-25T15:52:04.954805Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import lightgbm as lgb\n\n# Prepare the LightGBM Dataset\nlgb_train = lgb.Dataset(X_train, label=Y_train)\nlgb_val = lgb.Dataset(X_val, label=Y_val, reference=lgb_train)\n\n# Define parameters for the model\nparams = {\n    \"objective\": \"rmse\",          # Same as 'objective' in LGBMRegressor\n    \"boosting_type\": \"gbdt\",      # Default boosting type\n    \"learning_rate\": 0.02,        # Same as in LGBMRegressor\n    \"device\": \"gpu\",              # Enable GPU\n    \"metric\": \"rmse\"              # Evaluation metric\n}\n\n# Train the model using lgb.train()\nmodel = lgb.train(\n    params, \n    lgb_train, \n    num_boost_round=1000,             # Same as n_estimators\n    valid_sets=[lgb_train, lgb_val],  # Validation data for evaluation\n    callbacks=[lgb.early_stopping(stopping_rounds=50),\n               lgb.log_evaluation(100)])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:52:18.458273Z","iopub.execute_input":"2025-01-25T15:52:18.458556Z","iopub.status.idle":"2025-01-25T15:57:43.755217Z","shell.execute_reply.started":"2025-01-25T15:52:18.458535Z","shell.execute_reply":"2025-01-25T15:57:43.754467Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get final results\npredictions = model.predict(X_test)\npredicitons_df = X_test.copy()\npredicitons_df['predictions'] = predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:58:20.359423Z","iopub.execute_input":"2025-01-25T15:58:20.359773Z","iopub.status.idle":"2025-01-25T15:58:26.777673Z","shell.execute_reply.started":"2025-01-25T15:58:20.359745Z","shell.execute_reply":"2025-01-25T15:58:26.776749Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_df = pd.read_csv(DIRECTORY + 'test.csv')\nsubmission_df = submission_df.merge(predicitons_df, on=['shop_id', 'item_id'], how='left')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:58:35.793831Z","iopub.execute_input":"2025-01-25T15:58:35.794132Z","iopub.status.idle":"2025-01-25T15:58:35.985629Z","shell.execute_reply.started":"2025-01-25T15:58:35.794108Z","shell.execute_reply":"2025-01-25T15:58:35.984947Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_df[['ID', 'predictions']].rename(columns={'predictions': 'item_cnt_month'}).to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:59:17.12198Z","iopub.execute_input":"2025-01-25T15:59:17.122299Z","iopub.status.idle":"2025-01-25T15:59:17.555321Z","shell.execute_reply.started":"2025-01-25T15:59:17.122266Z","shell.execute_reply":"2025-01-25T15:59:17.554174Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Look at Results & What to Improve","metadata":{}},{"cell_type":"code","source":"predictions = model.predict(X_test)\nmean_squared_error(predictions, Y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T22:41:51.145131Z","iopub.execute_input":"2025-01-24T22:41:51.145412Z","iopub.status.idle":"2025-01-24T22:41:58.249317Z","shell.execute_reply.started":"2025-01-24T22:41:51.145391Z","shell.execute_reply":"2025-01-24T22:41:58.248714Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ax = lgb.plot_importance(model, max_num_features=20)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T22:42:11.668723Z","iopub.execute_input":"2025-01-24T22:42:11.669034Z","iopub.status.idle":"2025-01-24T22:42:12.107905Z","shell.execute_reply.started":"2025-01-24T22:42:11.669014Z","shell.execute_reply":"2025-01-24T22:42:12.106868Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_df = pd.concat([X_test, Y_test], axis=1)\nresults_df['predictions'] = predictions\n\n# Mark the type based on item-id, shop-id\n# new items: items have never been seen before date block == 33\n# seen before item/shop: item-shop combo is present with date block < 33\n# not see before: all else\n\nseen_before = final_df[(final_df['month_sales'] > 0) & (final_df['date_block_num'] < 33)] \\\n                    [['item_id', 'shop_id']].drop_duplicates().to_pandas()\nindicator = results_df.merge(seen_before, on=['item_id', 'shop_id'], how='left', indicator=True)['_merge']\nresults_df['old_combo'] = np.array(indicator == 'both')\n\nitems_new = results_df.merge(seen_before['item_id'].drop_duplicates(), on='item_id', how='left', indicator=True)['_merge']\nresults_df['new_item'] = np.array(items_new == 'left_only')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T18:02:20.998058Z","iopub.execute_input":"2025-01-24T18:02:20.998419Z","iopub.status.idle":"2025-01-24T18:02:21.517937Z","shell.execute_reply.started":"2025-01-24T18:02:20.99839Z","shell.execute_reply":"2025-01-24T18:02:21.516992Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T18:02:25.290156Z","iopub.execute_input":"2025-01-24T18:02:25.290456Z","iopub.status.idle":"2025-01-24T18:02:25.534276Z","shell.execute_reply.started":"2025-01-24T18:02:25.290431Z","shell.execute_reply":"2025-01-24T18:02:25.533425Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_df['type'] = np.where(results_df['old_combo'], 'old_combo', np.where(results_df['new_item'], 'new_item', 'zero'))\n\nresults_df['mse'] = (results_df['month_sales'] - results_df['predictions'])**2\nresults_df.groupby(by='type')[['mse', 'predictions', 'month_sales']].agg(['count', 'mean', 'sum'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T18:04:44.777797Z","iopub.execute_input":"2025-01-24T18:04:44.77813Z","iopub.status.idle":"2025-01-24T18:04:45.138664Z","shell.execute_reply.started":"2025-01-24T18:04:44.778072Z","shell.execute_reply":"2025-01-24T18:04:45.137781Z"}},"outputs":[],"execution_count":null}]}