{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = './data/'\n",
    "categories = pd.read_csv(DIRECTORY + 'item_categories.csv')\n",
    "items = pd.read_csv(DIRECTORY + 'items.csv')\n",
    "shops = pd.read_csv(DIRECTORY + 'shops.csv')\n",
    "train = pd.read_csv(DIRECTORY + 'sales_train.csv', parse_dates=['date'], date_format='%d.%m.%Y')\n",
    "test = pd.read_csv(DIRECTORY + 'test.csv')\n",
    "train['month'] = train['date'].dt.to_period('M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Test new items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get new items in \n",
    "new_items = np.setdiff1d(test['item_id'].unique(), train['item_id'].unique())\n",
    "len(new_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count\n",
       "(0, 1]         0.472391\n",
       "(1, 2]         0.195925\n",
       "(2, 3]         0.098819\n",
       "(3, 5]         0.091965\n",
       "(5, 10]        0.075400\n",
       "(10, 100]      0.063024\n",
       "(100, 1000]    0.002475\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of each \n",
    "items['subcategory'] = items['item_name'].str.split().str[0]\n",
    "count_categories = items['subcategory'].value_counts()\n",
    "pd.cut(count_categories, bins=[0,1,2,3,5,10,100,1000]).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nov. 2014 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try testing on Nov. 2014\n",
    "# predict the avg. of the ones with the same first name\n",
    "# predict avg. of ones in same category\n",
    "\n",
    "nov = pd.to_datetime('2014-11-01').to_period('M')\n",
    "nov_train = train[train['month'] == nov]\n",
    "nov_new_items = np.setdiff1d(nov_train['item_id'].unique(), train[train['month'] < nov]['item_id'].unique())\n",
    "nov_stores = nov_train['shop_id'].unique()\n",
    "nov_train_new = nov_train[nov_train['item_id'].isin(nov_new_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.711347826086957"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nov_train_aggregated = nov_train_new.groupby(['shop_id', 'item_id'])['item_cnt_day'].sum().to_frame('answers').reset_index()\n",
    "nov_train_aggregated['clipped'] = np.clip(nov_train_aggregated['answers'], 0, 20)\n",
    "np.square(nov_train_aggregated['clipped']).sum() / len(nov_stores) / len(nov_new_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.694565217391306"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guessing a constant value (only down to 9.7)\n",
    "guess = nov_train_aggregated['clipped'].sum() / len(nov_stores) / len(nov_new_items)\n",
    "np.square(nov_train_aggregated['clipped'] - 1).sum() / len(nov_stores) / len(nov_new_items) + 1 - len(nov_train_aggregated) / len(nov_stores) / len(nov_new_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guess based on previous first month sales\n",
    "before_nov = train[train['month'] < nov].copy()\n",
    "\n",
    "# calculate first month sales for each item, before grouping by item first name\n",
    "first_month_map = before_nov.groupby(['item_id'])['month'].min() # for each item, get its first month\n",
    "before_nov['first_month'] = before_nov['item_id'].map(first_month_map)\n",
    "first_month_sales = before_nov[before_nov['month'] == before_nov['first_month']].groupby(['item_id', 'shop_id'])['item_cnt_day'].sum().to_frame('first_month_sales').reset_index()\n",
    "first_month_sales = first_month_sales.merge(items, on=['item_id'], how='left')\n",
    "# by category, and by subcategory\n",
    "\n",
    "by_category = first_month_sales.groupby(['item_category_id', 'shop_id'])['first_month_sales'].mean().to_frame('prediction_category').reset_index()\n",
    "by_category['prediction_category'] = np.clip(by_category['prediction_category'], 0, 20)\n",
    "\n",
    "by_subcategory = first_month_sales.groupby(['subcategory', 'shop_id'])['first_month_sales'].mean().to_frame('prediction_subcategory').reset_index()\n",
    "by_subcategory['prediction_subcategory'] = np.clip(by_subcategory['prediction_subcategory'], 0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 10.711347826086957\n",
      "Category: 5.35224058262912\n",
      "Subcategory: 7.012970642423381\n"
     ]
    }
   ],
   "source": [
    "# guessing avg. of first month for same category\n",
    "prediction_df = nov_train_aggregated.merge(items, on=['item_id'], how='left').merge(by_category, on=['item_category_id', 'shop_id'], how='left')\n",
    "prediction_df = prediction_df.merge(by_subcategory, on=['subcategory', 'shop_id'], how='left')\n",
    "print(\"Baseline:\", np.square(prediction_df['clipped']).sum() / len(nov_stores) / len(nov_new_items))\n",
    "print(\"Category:\", np.square(prediction_df['clipped'] - prediction_df['prediction_category'].fillna(0)).sum() / len(nov_stores) / len(nov_new_items))\n",
    "print(\"Subcategory:\", np.square(prediction_df['clipped'] - prediction_df['prediction_subcategory'].fillna(0)).sum() / len(nov_stores) / len(nov_new_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional: 6.39447229299254\n"
     ]
    }
   ],
   "source": [
    "# either or\n",
    "prediction_df['na_conditional'] = np.where(prediction_df['prediction_subcategory'].isna(), prediction_df['prediction_category'], prediction_df['prediction_subcategory'])\n",
    "print(\"Conditional:\", np.square(prediction_df['clipped'] - prediction_df['na_conditional'].fillna(0)).sum() / len(nov_stores) / len(nov_new_items))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tradingClub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
